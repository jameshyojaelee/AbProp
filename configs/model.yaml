# Transformer model defaults.
vocab_size: 25  # 4 specials + 21 amino acid tokens
d_model: 256
nhead: 4
num_layers: 4
dropout: 0.1
max_position_embeddings: 1024
auxiliary_heads:
  cdr_frame_classifier: true
  liability_regressor: true
